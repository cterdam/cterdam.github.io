---
layout: single
title: "Ideas"
permalink: /ideas/
toc: true
toc_label: "Ideas"
toc_icon: "lightbulb"
toc_sticky: true
comments: true
---

In an interview, Sam Altman said if he were 22, he would feel like the luckiest
kid in all of history. For the empowered individual, there is simply an
overwhelming abundance of projects worth pursuing and a frustrating scarcity of
time to do them.

Since I haven't yet found a way to build everything myself (still trying to),
I'm open-sourcing my backlog. This is a list of (half-baked) project concepts
I'd love to see brought to life. Some of these are taken from somewhere else.
Feel free to steal anything.

## Information understanding

### Betting as a substitute for polling

- As a famous saying goes, "A bet is a tax on bullshit".
- Use distributions on betting platforms to understand real mass opinion, better
  than polls.
- Remember the 2024 election - instead of asking "what do you feel", asking
  "what do you think your neighbor would feel" gave much more accurate responses
  and the French trader Th√©o made a fortune. There is headroom in mass opinion
  understanding.

### Crowdsourced Hot Takes Newsletter

- A weekly newsletter where you ask founders or business leaders for their take
  on an important question and share their takes with readers.
- Reach out to influential voices in the tech or business space asking them some
  big questions e.g. When will we reach AGI, are we in an AI bubble etc.
- Send out a weekly edition where you share the responses to one of these
  questions from the different thought leaders polled.
- Business Model: Sponsored placements in each issue + premium membership for
  archive / search / tools.
- End Goal: Potential acquirers include Substack / Morning Brew / Axios /
  HubSpot, LinkedIn, or X. Target 4-6x revenue once brand and data moat are
  established.

### User data collection

- How to collect data from individuals (e.g. product reviews) when not everyone
  is willing to manually write reviews?
- The value of human beings might just boil down to data collection and data
  annotation. Annotation might be more effective and noise-free if it's done via
  passive participation such as simple things like games and captcha, or simply
  observing the decisions they make. This should be done without formally paying
  someone and asking them to intentionally label for your tasks.
- Because if you think about it, humans are doing data annotation tasks all day
  on their own anyways! That's all they ever do.

### Noise as a fingerprint of origin

- If a certain dataset contains a certain type of noise, what can we say / do?

## Modeling

### Distillation
