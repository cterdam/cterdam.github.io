---
title: "Month in mind: 2025 07"
categories: [monthly]
---

### A maniacal sense of urgency

In his book *Elon Musk*, Walter Isaacson highlights Musk’s relentless emphasis
on a “maniacal sense of urgency” as an operating principle. This is my
experience in this month. If you want to do something, you have to do it
immediately. If you don’t do it immediately, you will never have the chance to
do it. This motto was always true, but lately has been more true than before.

### Reinventing surfaces

It has been widely argued that modern AI has a capability surplus but an
integration deficit. But where can we find integration? Perplexity and OpenAI
take the lead to renew the browser war after nearly 8 years. Large models such
as Gemini release CLI clients, offering a novel interface than web apps,
capturing a different user base.

It seems with a saturation in power, distribution matters more. The surface
layer of our apps in 2025 is clearly in flux. As products begin to converge on
utility, they can only compete for a more upstream position in the information
distribution pipeline, which means rethinking their surface forms just in order
to get closer to the users. This is what we observe today playing out across
general-purpose utilities such as browsers and chatbot assistants, but also in
more fine-grained verticals like therapist AI products.

### There can never be a good time

The recent Windsurf drama reminds me of another company named after the chicken
and egg paradox. Chegg first went public in Nov 2013 at a price of $12.50. With
the pandemic and digital transformation boom, Chegg surged and hit an all-time
closing high of \>$110 in Feb 2021, and then quickly plunged to lose more than
80% of its value within a year. In the shadow of generative AI, as of 2025 its
stock is priced at ~$1, less than 1% of its historical peak.

It seems key developments that dominated Chegg’s rise and fall were not always
predictable. In the future, we could only expect increasingly so. How could one
have done better? When one acts reactively, less is in one’s control. When one
has less control, one can only compensate by being unpredictable. To me, this
tension might be the driving force behind the increasing volatility in how AI
practitioners make decisions today - and feeding a broader culture of
opportunism in the industry in general.

Have a great month!
